# Hey Raven Voice Assistant - Complete Environment Configuration
# Copy this file to .env and configure the values for your deployment

# ====================================
# REDIS CONFIGURATION (Shared)
# ====================================
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_DB=0

# ====================================
# TRANSCRIPTION-COLLECTOR CONFIGURATION
# ====================================
# Wake Word Detection
WAKE_WORD_CONFIG_PATH=/app/config/wake_word_config.json

# ====================================
# LLM-PROCESSOR CONFIGURATION
# ====================================
# Redis Streams
REDIS_INPUT_STREAM_NAME=hey_raven_commands
REDIS_OUTPUT_STREAM_NAME=llm_responses
REDIS_CONSUMER_GROUP=llm_processor_group
REDIS_STREAM_READ_COUNT=10
REDIS_STREAM_BLOCK_MS=2000

# Ollama Configuration
OLLAMA_HOST=localhost
OLLAMA_PORT=11434
OLLAMA_MODEL=mistral:7b
OLLAMA_API_TIMEOUT=60
OLLAMA_MAX_RETRIES=3

# LLM Response Configuration
MAX_RESPONSE_LENGTH=500
RESPONSE_TEMPERATURE=0.7
RAVEN_PERSONALITY_PROMPT=You are Raven, a helpful AI assistant integrated into a meeting system. Provide concise, helpful responses to questions during meetings. Keep responses brief and relevant to the meeting context.

# FastAPI Configuration
FASTAPI_HOST=0.0.0.0
FASTAPI_PORT=8000
LOG_LEVEL=INFO

# Model Pull Configuration
MODEL_PULL_VERBOSE=false
MODEL_PULL_PROGRESS_INTERVAL=10

# ====================================
# TTS-PROCESSOR CONFIGURATION
# ====================================
# Redis Streams
REDIS_INPUT_STREAM_NAME=llm_responses
REDIS_OUTPUT_STREAM_NAME=tts_audio_queue
REDIS_CONSUMER_GROUP=tts_processor_group
CONSUMER_NAME=tts-processor-main

# TTS Engine Configuration
TTS_ENGINE=gtts
TTS_LANGUAGE=en
TTS_SLOW_SPEECH=false
TTS_AUDIO_FORMAT=mp3

# Audio Processing Configuration
AUDIO_SAMPLE_RATE=22050
AUDIO_BITRATE=64k
MAX_AUDIO_DURATION=30
MAX_TEXT_LENGTH=1000

# TTS Performance Settings
TTS_TIMEOUT=10
TTS_RETRY_ATTEMPTS=3
TTS_RETRY_DELAY=1.0

# Audio Encoding Settings
AUDIO_ENCODING=base64
AUDIO_COMPRESSION=none

# ====================================
# VEXA-BOT CONFIGURATION
# ====================================
# Redis Configuration
REDIS_URL=redis://redis:6379/0

# TTS Audio Stream
TTS_AUDIO_STREAM_NAME=tts_audio_queue

# WhisperLive Configuration
WHISPER_LIVE_URL=ws://whisperlive:9090
WL_MAX_CLIENTS=10

# ====================================
# BOT-MANAGER CONFIGURATION
# ====================================
# Service URLs for bot management

# ====================================
# HEALTH CHECK CONFIGURATION
# ====================================
HEALTH_CHECK_INTERVAL=30

# ====================================
# MONITORING & LOGGING
# ====================================
LOG_LEVEL=INFO
LOG_FORMAT=json

# Performance Metrics
METRICS_ENABLED=true
METRICS_PORT=9090

# ====================================
# DEPLOYMENT CONFIGURATION
# ====================================
# Docker Configuration
COMPOSE_PROJECT_NAME=raven-ai

# Network Configuration
NETWORK_NAME=raven-network

# Volume Configuration
DATA_VOLUME=raven-data
MODEL_VOLUME=raven-models

# ====================================
# SECURITY CONFIGURATION
# ====================================
# JWT Configuration (if needed)
JWT_SECRET_KEY=your-secret-key-here
JWT_ALGORITHM=HS256
JWT_EXPIRE_MINUTES=30

# API Keys (if needed)
OPENAI_API_KEY=your-openai-key-here
GOOGLE_API_KEY=your-google-key-here

# ====================================
# DEVELOPMENT & TESTING
# ====================================
DEBUG=false
TESTING=false
DEV_MODE=false

# Test Configuration
TEST_MEETING_URL=https://meet.google.com/test
TEST_BOT_NAME=TestRaven


